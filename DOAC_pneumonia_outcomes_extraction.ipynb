{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c379784-8a47-40aa-8784-d4e969fb86e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary python modules\n",
    "import pandas as pd # v.1.4.3\n",
    "import numpy as np # v.1.4.3\n",
    "\n",
    "from tqdm import tqdm # v.4.65.0\n",
    "\n",
    "import math # python v.3.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef15e4-cdc7-4d34-9550-3d018fa9dd74",
   "metadata": {},
   "source": [
    "# Identifying the patient population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b27442-3202-443f-8257-d480c2c28ba2",
   "metadata": {},
   "source": [
    "To identify the patients with community aquired pneumonia (CAP), we selected for patients with pneumonia/pulmonary sepsis as their main admission diagnosis and with an ICU-admission <24h hours after hospital admission and who were admitted to the hospital either directly, via the emergency department, acute care/floor or the chest pain center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd41abf-add1-48ac-922c-76cd9e44ba96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat_all = pd.read_csv(\"../eICU_data/patient.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530a6563-b275-4fc8-9995-190d5b876483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pneumonia, bacterial',\n",
       " 'Pneumonia, aspiration',\n",
       " 'Pneumonia, other',\n",
       " 'Pneumonia, viral',\n",
       " 'Pneumonia, fungal',\n",
       " 'Pneumonia, parasitic (i.e., Pneumocystic pneumonia)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_pneumonias = [i for i in df_pat_all.apacheadmissiondx.value_counts().index.to_numpy() if \"Pneumonia\" in i]\n",
    "lst_pneumonias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e90ab0-4d12-422b-8798-96ad4d9088f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sepsis, pulmonary',\n",
       " 'Sepsis, renal/UTI (including bladder)',\n",
       " 'Sepsis, GI',\n",
       " 'Sepsis, unknown',\n",
       " 'Sepsis, cutaneous/soft tissue',\n",
       " 'Sepsis, other',\n",
       " 'Sepsis, gynecologic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df_pat_all.apacheadmissiondx.value_counts().index.to_numpy() if \"Sepsis\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9b1d12-59e9-470f-a145-72d035337e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst_pneumonias.append('Sepsis, pulmonary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5446da-0017-435a-8d72-2fa826fdbe12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pat_pneumonia = df_pat_all.loc[df_pat_all.apacheadmissiondx.isin(lst_pneumonias)\n",
    "                               & (df_pat_all.hospitaladmitoffset > (-60 * 24))\n",
    "                               & (df_pat_all.hospitaladmitsource.isin([\"Emergency Department\", \"Direct Admit\", \"Floor\", \"Acute Care/Floor\", \"Chest Pain Center\"]) | df_pat_all.hospitaladmitsource.isna())\n",
    "                               , :].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cd4c17-fcc7-419b-8ae1-5cb83ff1a32e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11317"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_pat_pneumonia = list(pat_pneumonia.patientunitstayid.unique())\n",
    "len(lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfd47a-262f-40da-94dd-26222c000b78",
   "metadata": {},
   "source": [
    "&rarr; 11317 ICU admissions with CAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6f68b1-63d5-4305-b812-49d359117c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiate the dataframe to which all the extracted information will be merged\n",
    "df_info = pd.DataFrame({\"patientunitstayid\": lst_pat_pneumonia})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e708fa-f04e-4f8e-81c8-27f680ae6bbc",
   "metadata": {},
   "source": [
    "# Reducing the file-size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b97b7c-f92f-473a-bcf9-8aa46ffa4040",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4cbad1-f2cb-42f5-8d75-68dec0ba1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reduced_files(import_path, export_path, notation, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes an import path (folder where all the eICU files are), an export path, a \"notation\" (will be added behind the file name as an identifier) and a list of ids, and then returns the reduced\n",
    "    files of eICU for only that population (except for the hospital table).\n",
    "\n",
    "    :param import_path: String - Folder where all the eICU data is stored.\n",
    "    \n",
    "    :param export_path: String - Should only include the folder, not the filename, and should end with \"/\".\n",
    "\n",
    "    :param notation: String - Short notation that will be added to each file name for future identification.\n",
    "\n",
    "    :param lst_ids: List - List of target population patientunitstayids.\n",
    "\n",
    "    :return: Saves a list of abbreviated dataframes to the specified export_path.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of all tables in the eICU database, except the hospital table as it is not connected to patientunitstayid\n",
    "    lst_tables = [\"admissionDrug\", \"admissionDx\", \"allergy\", \"apacheApsVar\", \"apachePatientResult\", \"apachePredVar\",\n",
    "                  \"carePlanCareProvider\", \"carePlanEOL\", \"carePlanGeneral\", \"carePlanGoal\", \"carePlanInfectiousDisease\", \"customLab\",\n",
    "                  \"diagnosis\", \"infusionDrug\", \"intakeOutput\", \"lab\", \"medication\", \"microLab\", \"note\",\n",
    "                  \"nurseAssessment\", \"nurseCare\", \"nurseCharting\", \"pastHistory\", \"patient\", \"physicalExam\",\n",
    "                  \"respiratoryCare\", \"respiratoryCharting\", \"treatment\", \"vitalAperiodic\", \"vitalPeriodic\"]\n",
    "\n",
    "    # Looping over all tables, selecting only the data pertaining to the cohort of interest and then saving these files in a specified location\n",
    "    for table in tqdm(lst_tables):\n",
    "        df_chunk = pd.read_csv(f\"{import_path}{table}.csv\", chunksize=100000, low_memory=False)\n",
    "        lst_dataframes = []\n",
    "        \n",
    "        for chunk in df_chunk:\n",
    "            df_temp = chunk[chunk[\"patientunitstayid\"].isin(lst_ids)]\n",
    "            lst_dataframes.append(df_temp)\n",
    "\n",
    "        df_small = pd.concat(lst_dataframes)\n",
    "        df_small.to_csv(f\"{export_path}{table}_{notation}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185c1a9-a24d-4207-acf9-55428e340d8e",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bc555e-8eb4-4c67-a9e0-955edca0542b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make_reduced_files(\n",
    "#    import_path = \"../eICU_data/\",\n",
    "#    export_path = \"data_pneumonia_doac/\",\n",
    "#    notation = \"pn_doac\",\n",
    "#    lst_ids = lst_pat_pneumonia\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a36a8-71f9-4d55-80e8-1141a5f5b6ba",
   "metadata": {},
   "source": [
    "To make this code work in your environment, the complete unpacked eICU data has to be located at the relative path \"../eICU_data/\" in your project.\n",
    "\n",
    "Now all of the data for the CAP patient cohort is in the folder at the relative path \"data_pneumonia_doac/\" and can be accessed from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e67ca1-e682-4eec-b165-62c30158f175",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b554ef0-1485-4d2c-be91-8c83a12ea17d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5a6ab9-9d70-444a-9e3a-b198054b52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_patient_info(df_pat, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes the patient dataframe of the eICU database, a list of target patientunitstayids and\n",
    "    returns a dataframe with \"cleaned\" info per patientunitstayid.\n",
    "\n",
    "    :param df_pat: DataFrame - Patient dataframe of eICU (or abbreviated). \n",
    "\n",
    "    :param lst_ids: List - List of the population patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with the information.\n",
    "    \"\"\"\n",
    "\n",
    "    lst_columns = [\"patientunitstayid\", \"uniquepid\", \"gender\", \"age\", \"hospitalid\", \"wardid\",\n",
    "                   \"unittype\", \"apacheadmissiondx\", \"hospitaldischargestatus\",\n",
    "                   'hospitaladmittime24', \"hospitaladmitsource\", \"hospitaldischargelocation\", 'unitadmittime24',\n",
    "                   'unitadmitsource', 'unitstaytype', 'dischargeweight', 'unitdischargelocation', 'unitdischargestatus', \"unitvisitnumber\"]\n",
    "\n",
    "    # reducing the general pat_df to reduce the computational load\n",
    "    df_temp = df_pat.loc[df_pat[\"patientunitstayid\"].isin(lst_ids), lst_columns].copy()\n",
    "\n",
    "    # gender column\n",
    "    df_temp[\"gender\"] = df_temp[\"gender\"].replace({\"Unknown\": np.nan, \"Other\": np.nan})\n",
    "\n",
    "    # age column\n",
    "    df_temp[\"age\"] = df_temp[\"age\"].replace(\"> 89\", \"90\")\n",
    "    df_temp[\"age\"] = pd.to_numeric(df_temp[\"age\"])\n",
    "    \n",
    "    df_final = df_temp[[\"patientunitstayid\", \"gender\", \"age\", \"apacheadmissiondx\",\"hospitaldischargestatus\", \"unitdischargestatus\", \n",
    "                        \"hospitaladmitsource\", \"unitadmitsource\", \"unitdischargelocation\"]].copy()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287c9e65-fe74-4043-9efa-c32e8b51dbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_icu_free_days(x, df_pat_ref):\n",
    "    ### this function is an apply function working row-wise. As one row represents one ICU-admission, this function only works on 1 ICU admission at a time\n",
    "    # variables to determine the other possible stays\n",
    "    uniquepid = x.uniquepid\n",
    "    visitnumber = x.unitvisitnumber\n",
    "    hospid = x.hospitalid\n",
    "    hospadmittime = x.hospitaladmittime24\n",
    "    hospadmitsource = x.hospitaladmitsource\n",
    "    hosp_year = x.hospitaldischargeyear\n",
    "    hospdischargetime = x.hospitaldischargetime24\n",
    "\n",
    "    # whether the patient died in the ICU/hospital, binary\n",
    "    unit_death = x.unitdischargestatus\n",
    "    hospital_death = x.hospitaldischargestatus\n",
    "\n",
    "    # Times in minutes from this unitadmission\n",
    "    hosp_discharge = x.hospitaldischargeoffset\n",
    "    orig_unit_discharge = x.unitdischargeoffset\n",
    "\n",
    "    # minutes after hospitaladmission that the patient was discharged. Negative as hospitaladmitoffset is negative to begin with!\n",
    "    dischargeoffset_from_hosp_admission = x.hospitaladmitoffset - x.unitdischargeoffset\n",
    "\n",
    "    # Number of minutes in 30 days, from the hospitaladmission. Negative as hospitaladmitoffset is negative to begin with!\n",
    "    maximum_hospoffset = x.hospitaladmitoffset - (60 * 24 * 30)\n",
    "\n",
    "    ### Looking for ICU-stays in the same hospital-stay after the current ICU-stay but starting before 30d from this ICU admission.\n",
    "    # the data has to be from the same patient (same uniquepid), has to be from the same hospital-stay overall which is identified by\n",
    "    # several several variables (hospitalid, hospitaladmittime etc.), has to be a visit after the current unitvisit (therefore higher visitnumber) and\n",
    "    # has to happen after the patient was discharged from the first visit (so the hospitaladmitoffset has to be smaller (as it is negative) than\n",
    "    # the minutes after hospitaladmission that the patient was discharged) and also has to happen before 30 days after the current ICU admission (so\n",
    "    # the hospitaladmitoffset has to be larger (as these are negative numbers) than 30 days after the current ICU-stays admission)\n",
    "    unique_ref_data = df_pat_ref.loc[(df_pat_ref.uniquepid == uniquepid) &\n",
    "                                     (df_pat_ref.hospitalid == hospid) &\n",
    "                                     (df_pat_ref.hospitaladmittime24 == hospadmittime) &\n",
    "                                     (df_pat_ref.hospitaladmitsource == hospadmitsource) &\n",
    "                                     (df_pat_ref.hospitaldischargeyear == hosp_year) &\n",
    "                                     (df_pat_ref.hospitaldischargetime24 == hospdischargetime) &\n",
    "\n",
    "                                     (df_pat_ref.unitvisitnumber > visitnumber) &\n",
    "                                     (df_pat_ref.hospitaladmitoffset < dischargeoffset_from_hosp_admission) &\n",
    "                                     (df_pat_ref.hospitaladmitoffset > maximum_hospoffset), :].copy().sort_values(\n",
    "        \"hospitaladmitoffset\", ascending=False)\n",
    "\n",
    "    # If there are stays after this ICU stay, save the corresponding admission-offsets and unit-durations as a list of tuples\n",
    "    if len(unique_ref_data) > 0:\n",
    "        lst_other_stays = list(zip(unique_ref_data[\"hospitaladmitoffset\"], unique_ref_data[\"unitdischargeoffset\"]))\n",
    "\n",
    "    # minutes per day\n",
    "    minutes_d = 60 * 24\n",
    "\n",
    "    # if the patient dies during the current ICU admission\n",
    "    if unit_death == 1:\n",
    "        return 0\n",
    "\n",
    "    # if the patient does not have any additional ICU-stays after this one\n",
    "    if len(unique_ref_data) == 0:\n",
    "\n",
    "        # if the patient has no other ICU admissions and does not dies in the hospital\n",
    "        if hospital_death == 0:\n",
    "            icu_free_days = ((30 * minutes_d) - orig_unit_discharge) / minutes_d\n",
    "\n",
    "            if icu_free_days < 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return icu_free_days\n",
    "\n",
    "        # if the patient has no other ICU admissions and dies in the hospital\n",
    "        if hospital_death == 1:\n",
    "\n",
    "            # if the patient has no other ICU admissions and dies in the hospital before the 30 days\n",
    "            if hosp_discharge < (30 * minutes_d):\n",
    "                icu_free_days = (hosp_discharge - orig_unit_discharge) / minutes_d\n",
    "\n",
    "                if icu_free_days < 0:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return icu_free_days\n",
    "\n",
    "            # if the patient has no other ICU admissions and dies in the hospital after the 30 days\n",
    "            else:\n",
    "                icu_free_days = ((30 * minutes_d) - orig_unit_discharge) / minutes_d\n",
    "\n",
    "                if icu_free_days < 0:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return icu_free_days\n",
    "\n",
    "    # if the patient has other ICU-stays after this one\n",
    "    else:\n",
    "        # calculate the end offset of the last ICU-stay (in minutes) from the current ICU admission\n",
    "        # There is no additional ICU-stay starting after 30d from the original ICU admission as we selected for this in the\n",
    "        # unique_ref_data above. Therefore, if a stay extends beyond the 30d, it will be the last one\n",
    "        last_stay_offset, last_stay_duration = lst_other_stays[-1]\n",
    "        end_last_stay = -1 * last_stay_offset + last_stay_duration + x.hospitaladmitoffset  # hospitaladmitoffsets are negative!\n",
    "\n",
    "        # if the last stay ends after the 30 days, adjust the duration of the last stay to end at the exact 30d mark\n",
    "        # (to streamline for calculations below)\n",
    "        if end_last_stay > (30 * minutes_d):\n",
    "            # calculate the duration that will simulate an end of the last ICU stay at 30d from the current ICU stay\n",
    "            dur_for_lst_stay_max_30d = ((30 * minutes_d) - x.hospitaladmitoffset) - (-1 * lst_other_stays[-1][0])\n",
    "\n",
    "            lst_other_stays[-1] = (lst_other_stays[-1][0], dur_for_lst_stay_max_30d)\n",
    "\n",
    "        # calculate the durations of the other ICU stays\n",
    "        duration_all_other_stays = sum([tup[1] for tup in lst_other_stays])\n",
    "\n",
    "        # if the patient has other ICU-stays after this one and the last ICU discharge of this hospital-admission is after 30 days\n",
    "        if end_last_stay > (30 * minutes_d):\n",
    "            icu_free_days = ((30 * minutes_d) - orig_unit_discharge - duration_all_other_stays) / minutes_d\n",
    "\n",
    "            if icu_free_days < 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return icu_free_days\n",
    "\n",
    "        # if the patient has other ICU-stays after this one and the last ICU discharge of this hospital-admission is before 30 days\n",
    "        else:\n",
    "            # if the patient has other ICU-stays after this one, the last ICU discharge of this hospital-admission is before 30 days\n",
    "            # and the patient dies in the hospital\n",
    "            if hospital_death == 1:\n",
    "\n",
    "                # if the patient has other ICU-stays after this one, the last ICU discharge of this hospital-admission is before 30 days\n",
    "                # and the patient dies in the hospital before 30 days\n",
    "                if hosp_discharge < (30 * minutes_d):\n",
    "                    icu_free_days = (hosp_discharge - orig_unit_discharge - duration_all_other_stays) / minutes_d\n",
    "\n",
    "                    if icu_free_days < 0:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return icu_free_days\n",
    "\n",
    "                # if the patient has other ICU-stays after this one, the last ICU discharge of this hospital-admission is before 30 days\n",
    "                # and the patient dies in the hospital after 30 days\n",
    "                else:\n",
    "                    icu_free_days = ((30 * minutes_d) - orig_unit_discharge - duration_all_other_stays) / minutes_d\n",
    "\n",
    "                    if icu_free_days < 0:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return icu_free_days\n",
    "\n",
    "            # if the patient has other ICU-stays after this one, the last ICU discharge of this hospital-admission is before 30 days\n",
    "            # and the patient does not dies in the hospital\n",
    "            if hospital_death == 0:\n",
    "                icu_free_days = ((30 * minutes_d) - orig_unit_discharge - duration_all_other_stays) / minutes_d\n",
    "\n",
    "                if icu_free_days < 0:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return icu_free_days\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_icu_free_days(df_pat, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes the patient dataframe and a list of patientunitstasyids and returns a dataframe with the ICU-free-days (out of 30 days)\n",
    "\n",
    "    :param df_pat: Dataframe - Patient dataframe of eICU (or abbreviated)\n",
    "\n",
    "    :param lst_ids: List - list of populations patientunitstayids\n",
    "\n",
    "    :return: Dataframe (name of the result column: \"ICU_free_days\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_stays_ICU_free_d = df_pat.loc[\n",
    "        (df_pat.patientunitstayid.isin(lst_ids)),\n",
    "        [\"patientunitstayid\", \"hospitaldischargestatus\",\n",
    "         \"unitdischargestatus\", \"uniquepid\", \"unitvisitnumber\", \"hospitalid\", \"hospitaladmittime24\",\n",
    "         \"hospitaladmitsource\", \"hospitaldischargetime24\", \"hospitaldischargeyear\", \"hospitaladmitoffset\",\n",
    "         \"unitdischargeoffset\", \"hospitaldischargeoffset\"]].copy()\n",
    "\n",
    "    # changing the death-columns to an int-binary system to prepare for the calculation\n",
    "    df_stays_ICU_free_d.unitdischargestatus = df_stays_ICU_free_d.unitdischargestatus.map({\"Alive\": 0, \"Expired\": 1})\n",
    "    df_stays_ICU_free_d.hospitaldischargestatus = df_stays_ICU_free_d.hospitaldischargestatus.map(\n",
    "        {\"Alive\": 0, \"Expired\": 1})\n",
    "\n",
    "    # get a list of all the patient-ids (!= patientunitstayids) and reduce the patient dataframe by them (creating a reference df)\n",
    "    # Importantly, this will also include any other ICU-admissions of the same patient beside the current ICU-admissions\n",
    "    lst_uniqueids = list(df_stays_ICU_free_d.uniquepid.unique())\n",
    "    df_ref_for_map_ICU_free_d = df_pat[df_pat.uniquepid.isin(lst_uniqueids)].copy()\n",
    "\n",
    "    # calculate the ICU free days\n",
    "    df_stays_ICU_free_d[\"ICU_free_days\"] = df_stays_ICU_free_d.apply(\n",
    "        lambda x: apply_icu_free_days(x, df_ref_for_map_ICU_free_d), axis=1)\n",
    "\n",
    "    df_final = df_stays_ICU_free_d[[\"patientunitstayid\", \"ICU_free_days\"]].copy()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43868ef-46c1-446e-a6b3-31c3768dd5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_pmh_subcat(x, df, clm_name):\n",
    "    df_one_id = df.loc[(df.patientunitstayid == x), [clm_name]]\n",
    "    lst_diagnoses = df_one_id[clm_name].unique().tolist()\n",
    "    lst_diagnoses = [str(i) for i in lst_diagnoses if i is not None]\n",
    "    final_string = \"|\".join(lst_diagnoses)\n",
    "    return final_string\n",
    "\n",
    "def apply_split_and_rejoin_for_output(str_pmh):\n",
    "    lst_strings = str_pmh.split(\"/\")\n",
    "    lst_final = lst_strings[6:]\n",
    "\n",
    "    if len(lst_final) == 1:\n",
    "        return lst_final[0]\n",
    "\n",
    "    if len(lst_final) > 1:\n",
    "        joined = \"/\".join(lst_final)\n",
    "        return joined\n",
    "\n",
    "def get_pastHistory(df_pmh, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the pastHistory Dataframe from eICU or abbreviated and a list of target patientunitstayids and returns\n",
    "    a kind of longformat dataframe with the PMH.\n",
    "\n",
    "    :param df_pmh: DataFrame - pastHistory dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids from the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayids as the index and columns for each category of PMH\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary of prospective column names (key) and the string keys to the PMH-string-path of each disease (values)\n",
    "    dict_subcat_clms = {\n",
    "        'pmh_HT_with_treatment': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Hypertension Requiring Treatment'],\n",
    "        'pmh_cancer': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Cancer'],\n",
    "        'pmh_non_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Non-Insulin Dependent Diabetes'],\n",
    "        'pmh_COPD': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'COPD'],\n",
    "        'pmh_CHF': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Congestive Heart Failure'],\n",
    "        'pmh_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Insulin Dependent Diabetes'],\n",
    "        'pmh_arrhythmias': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Arrhythmias'],\n",
    "        'pmh_MI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Myocardial Infarction'],\n",
    "        'pmh_strokes': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Strokes'],\n",
    "        'pmh_renal_insuff': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Insufficiency'],\n",
    "        'pmh_PCI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Procedural Coronary Intervention'],\n",
    "        'pmh_card_valvular': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Valve disease'],\n",
    "        'pmh_asthma': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Asthma'],\n",
    "        'pmh_renal_failure': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Failure'],\n",
    "        'pmh_CA_bypass': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Coronary Artery Bypass'],\n",
    "        'pmh_home_o2': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Home Oxygen'],\n",
    "        'pmh_venous_thrombosis': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Venous Thrombosis'],\n",
    "        'pmh_angina': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Angina'],\n",
    "        'pmh_PE': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Pulmonary Embolism'],\n",
    "        'pmh_mmunosuppression_last_6m': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'Immunosuppression within past 6 months'],\n",
    "    }\n",
    "    \n",
    "    # reducing the general pastHistory df to reduce the computational load\n",
    "    df_temp = df_pmh.loc[df_pmh[\"patientunitstayid\"].isin(lst_ids), [\"patientunitstayid\", \"pasthistorypath\", \"pasthistoryvalue\"]].copy()\n",
    "\n",
    "    # Replace substrings in pasthistorypath (which would cause issues due to regex expressions later on)\n",
    "    df_temp[\"pasthistorypath\"] = df_temp[\"pasthistorypath\"].str.replace(\"Hematology/Oncology\", \"Hematology-Oncology\",\n",
    "                                                                        regex=True)\n",
    "    # list for the future columns\n",
    "    lst_columns = []\n",
    "\n",
    "    # Iterate over the individual diseases and check whether a patient has this PMH or not then saving this as a column to the list\n",
    "    for clm_name, key_phrases in tqdm(dict_subcat_clms.items()):\n",
    "        key1 = key_phrases[0]\n",
    "        key2 = key_phrases[1]\n",
    "\n",
    "        df_new_clm_raw = df_temp.loc[(df_temp['pasthistorypath'].str.contains(key1, na=False)) &\n",
    "                                     (df_temp['pasthistorypath'].str.contains(key2, na=False)), [\"patientunitstayid\", \"pasthistorypath\"]].copy().drop_duplicates()\n",
    "\n",
    "        df_new_clm_raw[\"output_pmh_path\"] = df_new_clm_raw[\"pasthistorypath\"].apply(lambda x: apply_split_and_rejoin_for_output(x))\n",
    "\n",
    "        df_new_clm_reference = df_new_clm_raw.copy()\n",
    "\n",
    "        df_new_clm_raw[clm_name] = df_new_clm_raw[\"patientunitstayid\"].apply(lambda x: group_pmh_subcat(x, df_new_clm_reference, \"output_pmh_path\"))\n",
    "\n",
    "        df_pat_w_data = df_new_clm_raw.loc[:, [\"patientunitstayid\", clm_name]].copy().drop_duplicates()\n",
    "\n",
    "        lst_pat_w_data = list(df_new_clm_raw.patientunitstayid.unique())\n",
    "        lst_pat_no_data = [x for x in lst_ids if x not in lst_pat_w_data]\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_no_data, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    # Concatenate all the columns and export this with the ids as another column  \n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "    df_final = df_final.reset_index()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c606f464-ba98-4d7a-96ba-a039c76939b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_initial_clean_apacheApsVar(df_apsVar, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the apacheApsVar Dataframe of the eICU database or abbreviated and a list of target patientunitstayids and\n",
    "    returns a dataframe with initially \"cleaned\" data: The -1 Values in several columns which denote for \"no data was\n",
    "    entered\" were set to np.nan. Additionally, a GCS column was added.\n",
    "\n",
    "    :param df_apsVar: DataFrame - apacheApsVar Dataframe from eICU or abreviated. \n",
    "\n",
    "    :param lst_ids: List - list of target patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "   \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apsVar.loc[df_apsVar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid','eyes', 'motor', 'verbal', 'meds']].copy()\n",
    "    \n",
    "    # set the missing data to NaN\n",
    "    lst_clms = ['eyes', 'motor', 'verbal', 'meds']\n",
    "    for clm in lst_clms:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "    \n",
    "    # create the GCS column\n",
    "    df_temp[\"GCS\"] = df_temp.eyes + df_temp.motor + df_temp.verbal\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid','eyes', 'motor', 'verbal', 'meds', \"GCS\"])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "                       \n",
    "    # Rename columns\n",
    "    rename_clms = ['eyes', 'motor', 'verbal', 'meds', \"GCS\"]\n",
    "    df_final = df_final.rename(columns={clm: \"aps_{}\".format(clm) for clm in rename_clms})\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3715643c-207b-45a8-8851-271067bfd37d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePredVar_basics(df_predvar, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePredVar Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_predvar: DataFrame - apachePredVar Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_predvar.loc[df_predvar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid', 'oobintubday1']].copy()\n",
    "    \n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'oobintubday1'])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "        \n",
    "    # Rename columns\n",
    "    rename_clms = ['oobintubday1']\n",
    "    df_final = df_final.rename(columns={clm: \"pred_{}\".format(clm) for clm in rename_clms})\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e7376a-15d9-4c4b-8b95-2d9435b66402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePatientResult_basics(df_apacheresult, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePatientResult Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_apacheresult: DataFrame - apachePatientResult Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apacheresult.loc[(df_apacheresult[\"apacheversion\"] == \"IVa\") & (df_apacheresult[\"patientunitstayid\"].isin(lst_ids)),\n",
    "                             ['patientunitstayid', 'apachescore','actualiculos', 'unabridgedhosplos', \"unabridgedactualventdays\"]].copy()\n",
    "\n",
    "    # set the missing data to NaN\n",
    "    lst_minus_ones = ['apachescore']\n",
    "    for clm in lst_minus_ones:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'apachescore','actualiculos', 'unabridgedhosplos', \"unabridgedactualventdays\"])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0534ea-28f4-4f55-918c-208d21c71d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_infusion_drugs(df_infusion, lst_ids, additional_dict=None, timeframe=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe indicating whether patients received certain medication classes within a specified timeframe.\n",
    "\n",
    "    :param df_infusion: DataFrame - infusionDrug Dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :param additional_dict: Dict - Additional/custom dictionary with the \"clm_name\": \"drugname|drugname|drugname\" format.\n",
    "\n",
    "    :param timeframe: Tuple, default is (0, 1440) - (lower offset, upper offset), offset bounds.\n",
    "\n",
    "    :return: DataFrame with the columns of who got which medication.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_offset, upper_offset = timeframe\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_infusion.query(\"patientunitstayid in @lst_ids and @lower_offset <= infusionoffset <= @upper_offset\").copy()\n",
    "\n",
    "    df_reduced.drugname = df_reduced.drugname.str.lower()\n",
    "\n",
    "    dict_drugs = {\n",
    "        \"infusion_vaso_ino\": 'epinephrine|adrenaline|norepinephrine|levophed|dobutamine|dobutrex|vasopressin|isoprotenerol|isuprel|phenylephrine|neo-synephrine|dopamine|milrinone'\n",
    "    }\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        dict_drugs.update(additional_dict)\n",
    "\n",
    "    lst_columns = []\n",
    "    \n",
    "    # loop over the the drug groups and look at whether patients received this as an infusion or not\n",
    "    for clm_name, drug_str in dict_drugs.items():\n",
    "\n",
    "        lst_pat_drug = df_reduced.loc[df_reduced.drugname.str.contains(drug_str), \"patientunitstayid\"].copy().unique().tolist()\n",
    "        lst_pat_wo_drug = [i for i in lst_ids if i not in lst_pat_drug]\n",
    "\n",
    "        df_pat_w_data = pd.DataFrame(lst_pat_drug, columns=['patientunitstayid'])\n",
    "        df_pat_w_data[clm_name] = 1\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_wo_drug, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03385827-e6cf-4ab6-9a49-989a19f4b316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_clean_data(array_labs):\n",
    "    \"\"\"\n",
    "    Discard outliers that are > median + 2 IQR or < median - 2 IQR\n",
    "\n",
    "    :param lst_values: List - list of values (eg. mean BPs from a certain timeframe of a patient)\n",
    "\n",
    "    :return: Array - numpy array of cleaned values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # to detect outliers \n",
    "    q25, q50, q75 = np.percentile(array_labs, [25, 50, 75])\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    cleaned_array = array_labs[(array_labs >= (q50 - 2 * iqr)) & (array_labs <= (q50 + 2 * iqr))].copy()\n",
    "\n",
    "    return cleaned_array\n",
    "\n",
    "\n",
    "def group_labs_whole_timeframe(x, agg_type, realistic_bounds):\n",
    "    np_labs = x.to_numpy()\n",
    "    lower_realistic, upper_realistic = realistic_bounds\n",
    "\n",
    "    if len(np_labs) == 1:\n",
    "        if lower_realistic <= np_labs[0] <= upper_realistic:\n",
    "            return np_labs[0]\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    if len(np_labs) <= 5:\n",
    "        cleaned_labs = np_labs[(np_labs >= lower_realistic) & (np_labs <= upper_realistic)].copy()\n",
    "\n",
    "        if len(cleaned_labs) == 0:\n",
    "            return np.nan\n",
    "\n",
    "        if len(cleaned_labs) == 1:\n",
    "            return cleaned_labs[0]\n",
    "\n",
    "        else:\n",
    "            if agg_type == \"first\":\n",
    "                return cleaned_labs[0]\n",
    "            if agg_type == \"median\":\n",
    "                return np.median(cleaned_labs)\n",
    "            if agg_type == \"max\":\n",
    "                return np.max(cleaned_labs)\n",
    "            if agg_type == \"min\":\n",
    "                return np.min(cleaned_labs)\n",
    "\n",
    "    else:\n",
    "        cleaned_labs = fast_clean_data(np_labs)\n",
    "\n",
    "        if agg_type == \"first\":\n",
    "            return cleaned_labs[0]\n",
    "        if agg_type == \"median\":\n",
    "            return np.median(cleaned_labs)\n",
    "        if agg_type == \"max\":\n",
    "            return np.max(cleaned_labs)\n",
    "        if agg_type == \"min\":\n",
    "            return np.min(cleaned_labs)\n",
    "\n",
    "\n",
    "def fast_clean_labs_general_offset(df_labs, lst_ids, offsets, dict_labs_info):\n",
    "    \"\"\"\n",
    "    Input the labs dataframe from the eICU, a list of ids of the target cohort and a dictionary with certain setting per laboratory value.\n",
    "    Receive laboratory parameters that are cleaned/aggregated per patientunitstayid\n",
    "    \n",
    "    :param df_labs: Dataframe -  dataframe containing the labs (labs dataframe from eICU or abbreviated)\n",
    "\n",
    "    :param lst_ids: List - List with the patientunitstayids\n",
    "\n",
    "    :param offsets: Tuple, (earlier offset, later offset) - target time period\n",
    "\n",
    "    :param dict_labs_info: Dictionary - in the format of\n",
    "        \"labname\": [(lower_bound, upper_bound), (lower_realistic, upper_realistic), aggregation], where:\n",
    "        the labname is a the string name of the lab value (contained in the \"labname\")\n",
    "        the (lower bound, upper bound) is the range for possible values (eg. for AST 0-1000000)\n",
    "        the (lower bound, upper bound) is the range for realistic values (eg. for AST 1-10000)\n",
    "        the aggreation is a string picklist \"first\", \"median\", \"max\", \"min\"\n",
    "\n",
    "    :return: Dataframe with each column representing an aggregated laboratory value (and the column \"patienunitstayid\")\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_offset, upper_offset = offsets\n",
    "    \n",
    "    #reduce the dataframe size to speed up the following calculation/lessen the computational load\n",
    "    df_lab = df_labs.loc[df_labs.patientunitstayid.isin(lst_ids) &\n",
    "                         df_labs.labname.isin(list(dict_labs_info.keys())) &\n",
    "                         (df_labs.labresultoffset >= lower_offset) & (df_labs.labresultoffset <= upper_offset), :].copy()\n",
    "\n",
    "    lst_individ_lab_clm = []\n",
    "\n",
    "    for lab_name, bounds in tqdm(dict_labs_info.items()):\n",
    "        lower_bound, upper_bound = bounds[0]\n",
    "        aggregation = bounds[2]\n",
    "\n",
    "        # reduction to only the current labname\n",
    "        df_temp = df_lab.loc[(df_lab.labname == lab_name) &\n",
    "                             (df_lab.labresult >= lower_bound) & (df_lab.labresult <= upper_bound), :].copy()\n",
    "\n",
    "        # sorting before reduction to make an option \"first\" possible\n",
    "        df_temp = df_temp.sort_values(by=[\"patientunitstayid\", \"labresultoffset\"])\n",
    "        df_temp = df_temp[[\"patientunitstayid\", \"labresult\"]].copy().dropna()\n",
    "\n",
    "        df_temp.labresult = df_temp.labresult.astype(\"float\")\n",
    "        \n",
    "        # group the values\n",
    "        df_grouped_lab = (df_temp\n",
    "                          .groupby([\"patientunitstayid\"])\n",
    "                          .agg(lambda x: group_labs_whole_timeframe(x, agg_type=aggregation, realistic_bounds=bounds[1]))\n",
    "                          .reset_index()\n",
    "                          .dropna()\n",
    "                          )\n",
    "\n",
    "        # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "        df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "\n",
    "        clm_name = f\"{lab_name}_{lower_offset}to{upper_offset}_{aggregation}\"\n",
    "        df_individ_lab_final = df_pat.merge(df_grouped_lab, on=\"patientunitstayid\", how=\"left\").rename(columns={\"labresult\": clm_name})\n",
    "\n",
    "        lst_individ_lab_clm.append(df_individ_lab_final)\n",
    "\n",
    "    lst_dfs_patids_index = [df.set_index(\"patientunitstayid\") for df in lst_individ_lab_clm]\n",
    "\n",
    "    df_final_all = pd.concat(lst_dfs_patids_index, axis=1)\n",
    "    df_final_all = df_final_all.reset_index()\n",
    "\n",
    "    return df_final_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28664c66-b784-4b32-865b-b7b02b6e4cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_clean_data(array_vitals):\n",
    "    \"\"\"\n",
    "    Discard outliers that are > (median + 2 IQR) or < (median - 2 IQR)\n",
    "\n",
    "    :param lst_values: List - list of values (eg. mean BPs from a certain timeframe of a patient)\n",
    "\n",
    "    :return: Array - numpy array of cleaned values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # to detect outliers for the patients own baseline:\n",
    "    q25, q50, q75 = np.percentile(array_vitals, [25, 50, 75])\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    cleaned_array = array_vitals[(array_vitals >= (q50 - 2 * iqr)) & (array_vitals <= (q50 + 2 * iqr))].copy()\n",
    "\n",
    "    return cleaned_array\n",
    "\n",
    "\n",
    "def groupby_vitals_per_hour(x, agg_timeunit):\n",
    "    \"\"\"\n",
    "    Discard outliers (apply fast_clean_data function ()) and then summarize the data in this timeframe as a\n",
    "    single value per patient\n",
    "    \"\"\"\n",
    "    np_hourly_vitals = x.to_numpy()\n",
    "\n",
    "    cleaned_hourly = fast_clean_data(np_hourly_vitals)\n",
    "\n",
    "    if agg_timeunit == \"median\":\n",
    "        hour_vital = np.median(cleaned_hourly)\n",
    "    if agg_timeunit == \"max\":\n",
    "        hour_vital = np.max(cleaned_hourly)\n",
    "    if agg_timeunit == \"min\":\n",
    "        hour_vital = np.min(cleaned_hourly)\n",
    "\n",
    "    return hour_vital\n",
    "\n",
    "\n",
    "def groupby_vitals_total(x, agg_total):\n",
    "    \"\"\"\n",
    "    Summarize the data in this timeframe as a single value per patient\n",
    "    \"\"\"\n",
    "    np_total_vitals = x.to_numpy()\n",
    "\n",
    "    if agg_total == \"median\":\n",
    "        total_vital = np.median(np_total_vitals)\n",
    "    if agg_total == \"max\":\n",
    "        total_vital = np.max(np_total_vitals)\n",
    "    if agg_total == \"min\":\n",
    "        total_vital = np.min(np_total_vitals)\n",
    "\n",
    "    return total_vital\n",
    "\n",
    "\n",
    "def fast_vitals_periodic(df_periodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60):\n",
    "    \"\"\"\n",
    "        Takes the vitalPeriodic table of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "        returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "        value. If looking at the temperature, there is the option to include all temperature measurements from the nurses charting (which often \n",
    "        primarily includes the temperature values of a patient. Pulsepressure is calculated from the respective BP_sys - BP_dia. (will \n",
    "        automatically use 20/300 (systolic) and 10/200 (diastolic) as bounds)\n",
    "        Accepted vitalnames: temperature, sao2, heartrate, respiration, cvp, etco2, systemicsystolic, systemicdiastolic, systemicmean, pasystolic, \n",
    "        padiastolic, pamean, icp\n",
    "\n",
    "        :param df_periodic: Dataframe - abbreviated (! unless a lot of free RAM) Dataframe of the vitalPeriodic table of eICU\n",
    "\n",
    "        :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "        :param vital_name: String - Column name of the vital \n",
    "\n",
    "        :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20,100) for fio2\n",
    "\n",
    "        :param offset: Tuple - (lower time offest, upper time offset)\n",
    "\n",
    "        :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit (if the\n",
    "                offset duration is longer than the timeunit)\n",
    "\n",
    "        :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "        \n",
    "        :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "\n",
    "        :return: Dataframe \n",
    "        \"\"\"\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples of the bounds \n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    # next reduction, incorporating the big offset bounds and the realistic bounds\n",
    "    df_temp = df_reduced.loc[\n",
    "        (df_reduced[vital_name] >= lower_realistic_bound) & (df_reduced[vital_name] <= upper_realistic_bound) &\n",
    "        (df_reduced[\"observationoffset\"] >= lower_offset) & (df_reduced[\"observationoffset\"] <= upper_offset),\n",
    "        [\"patientunitstayid\", \"observationoffset\", vital_name]].copy().dropna()\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0: \n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp.observationoffset = pd.cut(df_temp.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_hours = (df_temp\n",
    "                        .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                        .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                        .reset_index()\n",
    "                        .drop(columns=[\"observationoffset\"])\n",
    "                        .dropna()\n",
    "                        .groupby([\"patientunitstayid\"])\n",
    "                        .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                        .reset_index()\n",
    "                        )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_hours, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a989b829-492c-4265-8496-f6b050438f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_vitals_combined(df_periodic, df_aperiodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60):\n",
    "    \"\"\"\n",
    "    Takes the both the vitalPeriodic and Aperiodic tables of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "    returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "    value. Possible vitalnames: systolic, diastolic, mean_bp\n",
    "\n",
    "    :param df_periodic: Dataframe - vitalPeriodic Dataframe of the eICU Database (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param df_aperiodic: Dataframe - vitalAperiodic Dataframe (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "    :param vital_name: String, picklist - options \"systolic\", \"diastolic\", \"mean_bp\"\n",
    "\n",
    "    :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20, 250) for systolic\n",
    "\n",
    "    :param offset: Tuple - (lower time offest, time upper offset)\n",
    "\n",
    "    :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit\n",
    "    (if the offset-duration is longer than the timeunit)\n",
    "\n",
    "    :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "    \n",
    "    :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "\n",
    "    :return: Dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    # dictionary that sorts the vital_names to the respective names of the columns in the periodic and Aperiodic dfs\n",
    "    dict_vitalnames = {\n",
    "        \"systolic\": (\"systemicsystolic\", \"noninvasivesystolic\"),\n",
    "        \"diastolic\": (\"systemicdiastolic\", \"noninvasivediastolic\"),\n",
    "        \"mean_bp\": (\"systemicmean\", \"noninvasivemean\")\n",
    "    }\n",
    "\n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_reduced_periodic = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "    df_reduced_aperiodic = df_aperiodic[df_aperiodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples\n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    key_periodic, key_aperiodic = dict_vitalnames[vital_name]\n",
    "    df_temp_periodic = df_reduced_periodic.loc[\n",
    "        (df_reduced_periodic[key_periodic] >= lower_realistic_bound) & (df_reduced_periodic[key_periodic] <= upper_realistic_bound) &\n",
    "        (df_reduced_periodic[\"observationoffset\"] >= lower_offset) & (df_reduced_periodic[\"observationoffset\"] <= upper_offset),\n",
    "        [\"patientunitstayid\", \"observationoffset\", key_periodic]].copy().dropna().rename(columns={key_periodic: vital_name})\n",
    "    df_temp_aperiodic = df_reduced_aperiodic.loc[\n",
    "        (df_reduced_aperiodic[key_aperiodic] >= lower_realistic_bound) & (df_reduced_aperiodic[key_aperiodic] <= upper_realistic_bound) &\n",
    "        (df_reduced_aperiodic[\"observationoffset\"] >= lower_offset) & (df_reduced_aperiodic[\"observationoffset\"] <= upper_offset),\n",
    "        [\"patientunitstayid\", \"observationoffset\", key_aperiodic]].copy().dropna().rename(columns={key_aperiodic: vital_name})\n",
    "\n",
    "    df_temp_whole = pd.concat([df_temp_periodic, df_temp_aperiodic])\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0:\n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp_whole.observationoffset = pd.cut(df_temp_whole.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_all = (df_temp_whole\n",
    "                      .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                      .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                      .reset_index()\n",
    "                      .drop(columns=[\"observationoffset\"])\n",
    "                      .dropna()\n",
    "                      .groupby([\"patientunitstayid\"])\n",
    "                      .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                      .reset_index()\n",
    "                      )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_all, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27101ce6-ee85-4e79-93d9-f22d1ce11804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_time_to_death_from_unit_admit(x):\n",
    "    # if the patient did not die, return NaN\n",
    "    if x.hospitaldischargestatus == \"Alive\":\n",
    "        return np.nan\n",
    "\n",
    "    # if the patient died in the ICU then the time on ICU is the time-to-death\n",
    "    if x.unitdischargestatus == \"Expired\":\n",
    "        return x.actualiculos\n",
    "\n",
    "    # if the patient died in the hospital calculate the time to death by subtracting the time to ICU admission\n",
    "    if x.hospitaldischargestatus == \"Expired\":\n",
    "        time_to_death = x.unabridgedhosplos - (x.hospitaladmitoffset / (24 * 60))\n",
    "        return time_to_death\n",
    "\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def time_to_death_from_unit_admission(df_pat, df_apache_res, lst_ids):\n",
    "    \"\"\"\n",
    "    Compute the time to death from ICU-admission for a cohort of interest. Will return np.nan if the patient did not die and\n",
    "    for irregularities.\n",
    "\n",
    "    :param df_pat: Dataframe - patient dataframe of the eICU or abbreviated\n",
    "\n",
    "    :param df_apache_res: Dataframe - apachePatientResult dataframe of the eICU or abbreviated\n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids\n",
    "\n",
    "    return: Dataframe with 2 columns (patientunitstayids and time_to_death_unitadmit)\n",
    "    \"\"\"\n",
    "\n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_pat_red = df_pat.loc[df_pat.patientunitstayid.isin(lst_ids),\n",
    "                            [\"patientunitstayid\", \"hospitaldischargestatus\", \"unitdischargestatus\",\n",
    "                             \"hospitaladmitoffset\"]].copy()\n",
    "    df_apache_res_red = df_apache_res.loc[df_apache_res.patientunitstayid.isin(lst_ids),\n",
    "                                          [\"patientunitstayid\", 'actualiculos', 'unabridgedhosplos']].copy()\n",
    "\n",
    "    # merging both to have all these columns ready for the apply method\n",
    "    df_combined = pd.merge(left=df_pat_red, right=df_apache_res_red, how=\"left\", on=\"patientunitstayid\")\n",
    "    df_combined = df_combined.drop_duplicates()\n",
    "\n",
    "    # calculate the time-to-death in a row-wise approach\n",
    "    df_combined[\"time_to_death_unitadmit\"] = df_combined.apply(lambda x: apply_time_to_death_from_unit_admit(x), axis=1)\n",
    "\n",
    "    df_final = df_combined[[\"patientunitstayid\", \"time_to_death_unitadmit\"]].copy()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8601d40-e1c8-42ac-a220-294aeb42c7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_AKI_crea_rise_by_offset(y, df_ref):\n",
    "    \"\"\"\n",
    "    Mapping function to map over the crea values of one patient whether AKI occurered by the criteria \"increase in creatinine\"\n",
    "\n",
    "    :param y: int - index of the df_lab_pat -> is the converted to offset/current crea to circumvent the problem of duplicate entries\n",
    "    with the same offset\n",
    "\n",
    "    :param df_ref: Dataframe - reduced labs_pat Dataframe (only 1 pat-id!)\n",
    "\n",
    "    :return: Int - binary\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    offset = df_ref.at[y, \"labresultoffset\"]\n",
    "    current_crea = df_ref.at[y, \"labresult\"]\n",
    "\n",
    "    # retrograde approach to make it easier later to make the time-to-AKI calculation\n",
    "    df_timepoint = df_ref.loc[df_ref.labresultoffset.between((offset - 2880), offset), \"labresult\"] #2880 minutes are 48 hours\n",
    "\n",
    "    lst_previous_values = df_timepoint.tolist()\n",
    "\n",
    "    lst_AKI = [x for x in lst_previous_values if x >= (current_crea + 0.3)]\n",
    "\n",
    "    if len(lst_AKI) >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def map_AKI_crea_rise_offsetclm(x, df_ref):\n",
    "    \"\"\"\n",
    "    Mapping function to identify the time-to-AKI by the criterium \"increase in creatinine\"\n",
    "    \n",
    "    :param y: int - patientunitstayid\n",
    "    \n",
    "    :param df_ref: Dataframe - reduced labs_pat Dataframe \n",
    "    \n",
    "    :return: String - in the format \"offset|offset|....\" for all the AKIs identified\n",
    "    \"\"\"\n",
    "    df_lab_pat = df_ref.loc[(df_ref.patientunitstayid == x) & (df_ref.labresultoffset >= 0), :].copy()\n",
    "\n",
    "    if df_lab_pat.empty == True:\n",
    "        return np.nan\n",
    "\n",
    "    df_lab_pat = df_lab_pat.reset_index(drop=True)\n",
    "    df_ref_one_pat = df_lab_pat.copy()\n",
    "\n",
    "    df_lab_pat[\"AKI_crea_rise_one_pat\"] = df_lab_pat.index.map(lambda y: map_AKI_crea_rise_by_offset(y, df_ref_one_pat))\n",
    "\n",
    "    df_lab_AKI_offsets = df_lab_pat.loc[df_lab_pat[\"AKI_crea_rise_one_pat\"] == 1, \"labresultoffset\"].copy()\n",
    "    lst_offsets_AKI_crea_rise = df_lab_AKI_offsets.tolist()\n",
    "    lst_offsets_AKI_crea_rise_sorted = sorted(lst_offsets_AKI_crea_rise)\n",
    "\n",
    "    string_offsets = \"|\".join(str(i) for i in lst_offsets_AKI_crea_rise_sorted)\n",
    "\n",
    "    return string_offsets\n",
    "\n",
    "\n",
    "def map_AKI_crea_rise_all_pat(x, df_ref):\n",
    "    \"\"\"\n",
    "    Mapping function for all patients whether AKI occurered by the criteria \"increase in creatinine\"\n",
    "\n",
    "    :param x: int - patientunitstayid\n",
    "\n",
    "    :param df_ref: Dataframe - reduced labs Dataframe (but with all pat-ids)\n",
    "\n",
    "    :return: Int - binary\n",
    "    \"\"\"\n",
    "\n",
    "    df_lab_pat = df_ref.loc[(df_ref.patientunitstayid == x) & (df_ref.labresultoffset >= 0), :].copy()\n",
    "\n",
    "    if df_lab_pat.empty == True:\n",
    "        return np.nan\n",
    "\n",
    "    df_lab_pat = df_lab_pat.reset_index(drop=True)\n",
    "    df_ref_one_pat = df_lab_pat.copy()\n",
    "\n",
    "    df_lab_pat[\"AKI_crea_rise_one_pat\"] = df_lab_pat.index.map(lambda y: map_AKI_crea_rise_by_offset(y, df_ref_one_pat))\n",
    "    lst_values = df_lab_pat.AKI_crea_rise_one_pat.unique().tolist()\n",
    "\n",
    "    if 1 in lst_values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def map_AKI_diagnosis_offsets(x, df_diagnosis_ref):\n",
    "    \"\"\"\n",
    "    Mapping function to identify the time-to-AKI by the criterium \"increase in creatinine\"\n",
    "    \n",
    "    :param x: int - patientunitstayid\n",
    "    \n",
    "    :param df_diagnosis_ref: Dataframe - reduced diagnosis Dataframe \n",
    "    \n",
    "    :return: String - in the format \"offset|offset|....\" for all the AKIs identified\n",
    "    \"\"\"\n",
    "\n",
    "    df_diagnosis_one_pat = df_diagnosis_ref.loc[df_diagnosis_ref.patientunitstayid == x, \"diagnosisoffset\"]\n",
    "\n",
    "    if df_diagnosis_one_pat.empty == True:\n",
    "        return np.nan\n",
    "\n",
    "    lst_offsets = df_diagnosis_one_pat.tolist()\n",
    "    lst_offsets_sorted = sorted(lst_offsets)\n",
    "\n",
    "    string_offsets = \"|\".join(str(i) for i in lst_offsets_sorted)\n",
    "\n",
    "    return string_offsets\n",
    "\n",
    "\n",
    "\n",
    "def map_AKI_crea_baseline(x, df_ref):\n",
    "    \"\"\"\n",
    "    Mapping function for all patients whether AKI occurered by the criteria \"increase in creatinine-baseline\"\n",
    "\n",
    "    :param x: int - patientunitstayid\n",
    "\n",
    "    :param df_ref: Dataframe - reduced labs Dataframe (but with all pat-ids)\n",
    "\n",
    "    :return: Int - binary\n",
    "    \"\"\"\n",
    "    \n",
    "    df_lab_pat = df_ref[df_ref.patientunitstayid == x].copy()\n",
    "\n",
    "    if df_lab_pat.empty == True:\n",
    "        return np.nan\n",
    "\n",
    "    df_lab_pat = df_lab_pat.sort_values(by=[\"labresultoffset\"]).reset_index(drop=True)\n",
    "\n",
    "    df_labs_before_icu = df_lab_pat[df_lab_pat.labresultoffset <= 0].copy()\n",
    "\n",
    "    if df_labs_before_icu.empty == False:\n",
    "        crea_baseline = df_labs_before_icu.labresult.min()\n",
    "\n",
    "    else:\n",
    "        crea_baseline = df_lab_pat.at[0, \"labresult\"]\n",
    "\n",
    "    df_lab_pat_first_week = df_lab_pat[df_lab_pat.labresultoffset <= 10080]\n",
    "    lst_creas_first_week = df_lab_pat_first_week.labresult.tolist()\n",
    "\n",
    "    lst_aki_baseline = [i for i in lst_creas_first_week if i >= (crea_baseline * 1.5)]\n",
    "\n",
    "    if len(lst_aki_baseline) >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def find_AKI_pat(df_labs, df_diagnosis, lst_ids):\n",
    "    \"\"\"\n",
    "    Take a population (list of patientunitstayids), the labs table (for creatinine values), and the diagnosis table and return whether the patients\n",
    "    had an AKI event during their hospital stay\n",
    "\n",
    "    KDIGO:\n",
    "    Increase in serum creatinine by ≥0.3 mg/dL (≥26.5 micromol/L) within 48 hours \n",
    "\n",
    "    Increase in serum creatinine to ≥1.5 times baseline, which is known or presumed to have occurred within the prior seven days \n",
    "\n",
    "    Urine volume <0.5 mL/kg/hour for six hours -> do not use -> pretty bad reliability https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8486770/, therefore not implemented\n",
    "\n",
    "    + “acute renal failure” in the diagnosis chart of the eICU database\n",
    "\n",
    "\n",
    "    :param df_labs: Dataframe - labs dataframe \n",
    "\n",
    "    :param df_diagnosis: Dataframe - diagnosis Dataframe \n",
    "\n",
    "    :param lst_ids: list - list of target patientunitstayids\n",
    "\n",
    "    :return: Dataframe - with columns denoting where the AKI had been found (+ offsets/time to AKI)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # reduce the labs table to only contain the necessary values\n",
    "    df_labs = df_labs.loc[(df_labs.patientunitstayid.isin(lst_ids)) & (df_labs.labname == \"creatinine\"),\n",
    "                          [\"patientunitstayid\", \"labresultoffset\", \"labresult\"]].copy()\n",
    "    df_labs = df_labs.dropna()\n",
    "    df_ref_big = df_labs.copy()\n",
    "\n",
    "    df_pat = pd.DataFrame({\"patientunitstayid\": lst_ids})\n",
    "\n",
    "    ## for the acute crea increase\n",
    "    # whether they got an AKI from that\n",
    "    df_pat[\"AKI_crea_rise\"] = df_pat[\"patientunitstayid\"].map(lambda x: map_AKI_crea_rise_all_pat(x, df_ref_big))\n",
    "\n",
    "    # offsets for the acute crea increase\n",
    "    df_pat[\"AKI_crea_rise_offsets\"] = df_pat[\"patientunitstayid\"].map(lambda x: map_AKI_crea_rise_offsetclm(x, df_ref_big))\n",
    "\n",
    "    ## for the increase from baseline\n",
    "    # whether they got an AKI from that\n",
    "    df_pat[\"AKI_crea_baseline\"] = df_pat[\"patientunitstayid\"].map(lambda x: map_AKI_crea_baseline(x, df_ref_big))\n",
    "\n",
    "    ## via the diagnosis table\n",
    "    df_diagnosis = df_diagnosis.loc[(df_diagnosis.patientunitstayid.isin(lst_ids)) &\n",
    "                                    (df_diagnosis[\"diagnosisstring\"].str.contains(\"acute renal failure\")),\n",
    "                                    [\"patientunitstayid\", \"diagnosisoffset\"]].copy()\n",
    "    df_diagnosis = df_diagnosis.dropna()\n",
    "\n",
    "    ## if they ever had an entry to the diagnosis list\n",
    "    lst_pat_w_AKI_diagnosis_ever = df_diagnosis.patientunitstayid.unique().tolist()\n",
    "    df_pat[\"AKI_diagnosis_ever\"] = df_pat[\"patientunitstayid\"].map(lambda x: 1 if x in lst_pat_w_AKI_diagnosis_ever else 0)\n",
    "\n",
    "    ## whether they already had an AKI on admission (<24h) to the ICUin the diagnosis chart (for further differentiation/exclusion)\n",
    "    df_diagnosis_under1d = df_diagnosis[df_diagnosis.diagnosisoffset <= 1440].copy()\n",
    "    lst_pat_w_AKI_diagnosis_onadmission = df_diagnosis_under1d.patientunitstayid.unique().tolist()\n",
    "    df_pat[\"AKI_diagnosis_onadmission\"] = df_pat[\"patientunitstayid\"].map(lambda x: 1 if x in lst_pat_w_AKI_diagnosis_onadmission else 0)\n",
    "\n",
    "    ## offsets for the AKI by diagnosis chart \n",
    "    df_pat[\"AKI_diagnosis_offsets\"] = df_pat[\"patientunitstayid\"].map(lambda x: map_AKI_diagnosis_offsets(x, df_diagnosis))\n",
    "\n",
    "    return df_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28ea512f-52f6-4c36-95b3-d5f720b06b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dialysis_dialysisdays(df_intout, df_treat, df_pmh, lst_ids):\n",
    "    \"\"\"\n",
    "    Function that checks if patients got dialysis at some point during the stay and several other variables. It will export\n",
    "    1 column (boolean) called pmh_dialysis if the patient were listed as receiving dialysis under the pmh variable\n",
    "    renal failure. Then another boolean column if they received any dialysis at any point during their hospital stay\n",
    "    (any_dialysis_ever). Then a column treatment_chronic_dialysis (boolean) if they were listed as receiving dialysis\n",
    "    for chronic renal failure in the treatments dataframe. Then a column treatment_peritoneal_dialysis if they were\n",
    "    listed as receiving peritoneal dialysis at any point in the treatments dataframe.\n",
    "    And then a column dialysis_days that contains the number of seperate days that the patients received dialysis\n",
    "    (only full days). If a patient did not receive dialysis then it will contain np.nan\n",
    "\n",
    "    :param df_intout: Dataframe - IntakeOutput table from eICU\n",
    "    \n",
    "    :param df_treat: Dataframe - treatment table from eICU\n",
    "    \n",
    "    :param df_pmh: Dataframe - pasthistory table from eICU\n",
    "    \n",
    "    :param lst_ids: List - list of patientunitstayids\n",
    "    \n",
    "    :return: Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    lst_dialysis_treatments = [\n",
    "        'renal|dialysis|hemodialysis|for chronic renal failure',\n",
    "        'renal|dialysis|hemodialysis',\n",
    "        'renal|dialysis|hemodialysis|for acute renal failure',\n",
    "        'renal|dialysis|hemodialysis|emergent',\n",
    "        'renal|dialysis|C V V H D',\n",
    "        'renal|dialysis|insertion of venous catheter for hemodialysis',\n",
    "        'renal|dialysis|peritoneal dialysis',\n",
    "        'renal|dialysis|SLED',\n",
    "        'renal|dialysis|C V V H',\n",
    "        'renal|dialysis|ultrafiltration (fluid removal only)',\n",
    "        'renal|dialysis|peritoneal dialysis|emergent',\n",
    "        'renal|dialysis|peritoneal dialysis|for chronic renal failure',\n",
    "        'renal|electrolyte correction|treatment of hyperkalemia|dialysis',\n",
    "        'toxicology|drug overdose|drug removal measures|hemodialysis',\n",
    "        'renal|dialysis|ultrafiltration (fluid removal only)|for acute renal failure',\n",
    "        'renal|electrolyte correction|treatment of hyperphosphatemia|dialysis'\n",
    "    ]  # for the column treatmentstring in df_treatment\n",
    "\n",
    "    lst_peritoneal_dialysis_treatments = [\n",
    "        'renal|dialysis|peritoneal dialysis',\n",
    "        'renal|dialysis|peritoneal dialysis|emergent',\n",
    "        'renal|dialysis|peritoneal dialysis|for chronic renal failure',\n",
    "    ]  # for the column treatmentstring in df_treatment\n",
    "\n",
    "    lst_chronic_dialysis_treatments = [\n",
    "        'renal|dialysis|hemodialysis|for chronic renal failure',\n",
    "        'renal|dialysis|peritoneal dialysis|for chronic renal failure',\n",
    "    ]  # for the column treatmentstring in df_treatment\n",
    "\n",
    "    lst_dialysis_intout = [\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Dialysis (ml)|In',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Dialysis (ml)|Out',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Output (ml)|CRRT - UF removed',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Intake (ml)|Generic Intake (ml)|Hemodialysis Intake (mL)',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Output (ml)|CRRT Actual Pt Fluid Removed (\"C\")',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Output (ml)|Ultrafiltration',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Output (ml)|CRRT Out',\n",
    "        'flowsheet|Flowsheet Cell Labels|I&O|Output (ml)|HemodialysisOut'\n",
    "    ]  # for the column cellpath in df_intakeOutput\n",
    "\n",
    "    # reduce all dfs\n",
    "    df_pmh_red = df_pmh[df_pmh[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "    df_treat_red = df_treat[df_treat[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "    df_intout_red = df_intout[df_intout[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # get whether patients had a history of renal failure with dialysis\n",
    "    df_pmh_result = get_pastHistory(df_pmh_red, lst_ids)\n",
    "    df_pmh_result[\"pmh_dialysis\"] = df_pmh_result.pmh_renal_failure.map(lambda x: 1 if \"dialysis\" in str(x) else 0)\n",
    "\n",
    "    # initialize the then final dataframe\n",
    "    df_final_res = df_pmh_result[[\"patientunitstayid\", \"pmh_dialysis\"]].copy()\n",
    "\n",
    "    # calculate whether patients got dialysis at all\n",
    "    df_treat_dialysis = df_treat_red[df_treat_red.treatmentstring.isin(lst_dialysis_treatments)].copy()\n",
    "    lst_treat_dialysis = list(df_treat_dialysis.patientunitstayid.unique())\n",
    "\n",
    "    df_intout_dialysis = df_intout_red[df_intout_red.cellpath.isin(lst_dialysis_intout)].copy()\n",
    "    lst_intout_dialysis = list(df_intout_dialysis.patientunitstayid.unique())\n",
    "\n",
    "    lst_patids_dialysis = list(set(lst_treat_dialysis + lst_intout_dialysis))\n",
    "    df_final_res[\"any_dialysis_ever\"] = df_final_res.patientunitstayid.map(lambda x: 1 if x in lst_patids_dialysis else 0)\n",
    "\n",
    "    # calculate who was charted as chronic renal failure in the treatments df\n",
    "    lst_patids_chronic_treat = list(df_treat_red[df_treat_red.treatmentstring.isin(lst_chronic_dialysis_treatments)].patientunitstayid.unique())\n",
    "    df_final_res[\"treatment_chronic_dialysis\"] = df_final_res.patientunitstayid.map(lambda x: 1 if x in lst_patids_chronic_treat else 0)\n",
    "\n",
    "    # add peritoneal dialysis in the treatment df as an extra column\n",
    "    lst_patids_peritoneal_treat = list(df_treat_red[df_treat_red.treatmentstring.isin(lst_peritoneal_dialysis_treatments)].patientunitstayid.unique())\n",
    "    df_final_res[\"treatment_peritoneal_dialysis\"] = df_final_res.patientunitstayid.map(lambda x: 1 if x in lst_patids_peritoneal_treat else 0)\n",
    "\n",
    "    # calculate how many days the patients actually got dialysis\n",
    "    df_treat_days = df_treat_dialysis.loc[df_treat_dialysis.treatmentoffset >= 0, [\"patientunitstayid\", \"treatmentoffset\"]].copy()\n",
    "    df_treat_days = df_treat_days.rename(columns={\"treatmentoffset\": \"offset\"})\n",
    "\n",
    "    df_intout_days = df_intout_dialysis.loc[df_intout_dialysis.intakeoutputoffset >= 0, [\"patientunitstayid\", \"intakeoutputoffset\"]].copy()\n",
    "    df_intout_days = df_intout_days.rename(columns={\"intakeoutputoffset\": \"offset\"})\n",
    "\n",
    "    df_days = pd.concat([df_treat_days, df_intout_days], axis=0)\n",
    "\n",
    "    df_days.offset = df_days.offset // 1440\n",
    "\n",
    "    df_days_grouped = df_days.groupby('patientunitstayid')['offset'].nunique().reset_index()\n",
    "    df_days_grouped = df_days_grouped.rename(columns={\"offset\": \"dialysis_days\"})\n",
    "\n",
    "    # merge the dialysis days column to the final dataframe\n",
    "    df_final_res = df_final_res.merge(right=df_days_grouped, how=\"left\", on=\"patientunitstayid\")\n",
    "\n",
    "    return df_final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402de11-8d44-4f36-9688-a33e634da857",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identifying the patients on DOAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e38be48-c754-4c42-b6b7-317d124f9a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_meds_admission_pneumonia = pd.read_csv(\"data_pneumonia_doac/admissionDrug_pn_doac.csv\", low_memory=False) \n",
    "df_active_medication = pd.read_csv(\"data_pneumonia_doac/medication_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe52796-7073-4b56-965e-ffb738c8d5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the lists/dictionaries of the DOAC brand and generic names\n",
    "lst_doacs = [\n",
    "    \"dabigatran\", \"pradaxa\", \n",
    "    \"rivaroxaban\", \"xarelto\",\n",
    "    \"apixaban\", \"eliquis\",\n",
    "    \"edoxaban\", \"savaysa\", \"lixiana\",\n",
    "    \"betrixaban\", \"bevyxxa\"\n",
    "]\n",
    "\n",
    "dict_doacs = {\n",
    "    \"pradaxa\": \"dabigatran\", \n",
    "    \"xarelto\": \"rivaroxaban\",\n",
    "    \"eliquis\": \"apixaban\",\n",
    "    \"savaysa\": \"edoxaban\",\n",
    "    \"lixiana\": \"edoxaban\",\n",
    "    \"bevyxxa\": \"betrixaban\",\n",
    "    \"dabigatran\" : \"dabigatran\", \n",
    "    \"rivaroxaban\" : \"rivaroxaban\",\n",
    "    \"apixaban\" : \"apixaban\",\n",
    "    \"edoxaban\" : \"edoxaban\",\n",
    "    \"betrixaban\" : \"betrixaban\"\n",
    "}\n",
    "\n",
    "lst_doacs_regex = \"|\".join(lst_doacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5641569d-3fff-4caf-83e4-52763f763d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_doac_generic_name(x, dict_doacs):\n",
    "    \"\"\"Mapping the brand names of the DOAC to their generic names\"\"\"\n",
    "    \n",
    "    brand_str = x.strip().lower()\n",
    "    lst_generic_str = brand_str.split()\n",
    "    lst_doac_brand_name = [i for i in dict_doacs.keys() if i in lst_generic_str]\n",
    "    \n",
    "    if len(lst_doac_brand_name) >0 :\n",
    "        return dict_doacs[lst_doac_brand_name[0]]\n",
    "    else:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "036f752c-fd8a-4698-8422-80ec59c9901a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering for patients who were reported to receive DOAC prior to their admission to the ICU (reported before 48h in the ICU)\n",
    "df_doacs_admissiondrug_pneumonia = df_meds_admission_pneumonia[(df_meds_admission_pneumonia.drugname.str.contains(lst_doacs_regex, regex=True, case=False)) \n",
    "                                                               & (df_meds_admission_pneumonia.drugoffset < (48*60))].copy()\n",
    "df_doacs_admissiondrug_pneumonia[\"generic_name\"] = df_doacs_admissiondrug_pneumonia.drugname.map(lambda x: map_doac_generic_name(x, dict_doacs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f4bf65-3ba9-4a70-aa18-1efd3d82d914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_doac_admissiondrug_patstays = list(df_doacs_admissiondrug_pneumonia.patientunitstayid.unique())\n",
    "len(lst_doac_admissiondrug_patstays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b2b6c-4917-4110-a6da-c87ca4049a11",
   "metadata": {},
   "source": [
    "125 Patients on DOACs identified from the table admission-drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "649f192b-e078-4cb1-9faa-b372f76e5418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35915: 'rivaroxaban', 37792: 'apixaban', 35604: 'dabigatran'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the HICL-Seq No associated with the the DOACs identified in the admissionDrug table for later use and save them as list/dictionary\n",
    "df_hicl = df_doacs_admissiondrug_pneumonia[[\"drughiclseqno\", \"generic_name\"]].value_counts().reset_index()\n",
    "dict_hicl_doac = dict(zip(df_hicl.drughiclseqno,df_hicl.generic_name))\n",
    "lst_doac_hicl = list(df_hicl.drughiclseqno.unique())\n",
    "dict_hicl_doac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "465cd747-c6e8-4705-84a9-d33c80780cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare a dataframe with 2 columns patientunitstayid and generic name of the specific DOAC to get/preserve the information which patient received which specific DOAC \n",
    "# (recorded on the admission drug table)\n",
    "df_doac_admdrug_for_merge = df_doacs_admissiondrug_pneumonia.groupby(\"patientunitstayid\")[\"generic_name\"].first().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "449e1b3f-fab4-4ceb-8186-0601bb3fb4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering for patients who were reported to receive DOAC on admission to the ICU (during the first 48h in the ICU)\n",
    "df_active_medication_doacs = df_active_medication.loc[(df_active_medication.drughiclseqno.isin(lst_doac_hicl) | \n",
    "                                                      df_active_medication.drugname.str.contains(lst_doacs_regex, regex=True, case=False)) & \n",
    "                                                      (df_active_medication.drugorderoffset < (60*48)), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f95600-d4e1-420c-9aa6-333eaf59a80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_doac_active_meds_patstays = list(df_active_medication_doacs.patientunitstayid.unique())\n",
    "len(lst_doac_active_meds_patstays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12699b-a79e-479b-a9e1-ccadfd82c9a4",
   "metadata": {},
   "source": [
    "186 Patients on DOACs identified from the table active medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f4f453-8cc2-4b63-9a54-925add922fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare a dataframe with 2 columns patientunitstayid and generic name of the specific DOAC to get/preserve the information which patient received which specific DOAC \n",
    "# (recorded on the active medication table)\n",
    "df_active_medication_doacs[\"drughiclseqno\"] = df_active_medication_doacs[\"drughiclseqno\"].astype(int)\n",
    "df_active_medication_doacs[\"generic_name\"] = df_active_medication_doacs[\"drughiclseqno\"].map(dict_hicl_doac)\n",
    "\n",
    "df_doac_active_meds_for_merge = df_active_medication_doacs.groupby(\"patientunitstayid\")[\"generic_name\"].first().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2e36852-80ff-4773-af8b-81382b9aff0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both lists of IDs with DOACs and delete duplicates\n",
    "lst_all_doac_patids = list(set(lst_doac_admissiondrug_patstays) | set(lst_doac_active_meds_patstays))\n",
    "len(lst_all_doac_patids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48039d11-eaed-4524-b82c-389726a7a8c8",
   "metadata": {},
   "source": [
    "In total 273 Patients on DOACs identified (who also had CAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6c991e9-f0e7-440e-b106-2ce370f4806e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the information on the individual DOACs taken by the patients from both the admission drug and active medications table\n",
    "df_individ_doac = (pd.concat([df_doac_active_meds_for_merge, df_doac_admdrug_for_merge])).drop_duplicates()\n",
    "len(df_individ_doac.patientunitstayid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0508801-aa52-4df3-bd81-d1a7097f4580",
   "metadata": {},
   "source": [
    "Same number of unique IDs after dropping the duplicates -> no conflicting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7d36a04-79b0-4d32-b4c2-711e9922cdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the information on the DOAC to the growing Dataframe of the extracted data (both binary and the specific type of DOAC)\n",
    "df_info[\"doac_binary\"] = 0\n",
    "df_info.loc[df_info.patientunitstayid.isin(lst_all_doac_patids), \"doac_binary\"] = 1\n",
    "\n",
    "df_info = df_info.merge(right=df_individ_doac, how=\"left\", on=\"patientunitstayid\").rename(columns={\"generic_name\":\"specific_doac\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a3d3dea-53ad-475a-9766-e9f38b143644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rivaroxaban    160\n",
       "apixaban        74\n",
       "dabigatran      39\n",
       "Name: specific_doac, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numbers of ICU-admission with the specific DOACs\n",
    "df_info.specific_doac.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7ff60-d476-4d79-aba4-d263ff5f62e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02a4526f-e75a-4099-b67a-fe764b0af2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_patient_doac = pd.read_csv(\"data_pneumonia_doac/patient_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cc53916-0584-4b82-bdde-7b00a386056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat_res = get_basic_patient_info(df_patient_doac, lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ae98286-07af-4c44-bf72-998f5998be66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the result \n",
    "df_pat_res.hospitaldischargestatus = df_pat_res.hospitaldischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "df_pat_res.unitdischargestatus = df_pat_res.unitdischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "df_pat_res.gender = df_pat_res.gender.map({\"Male\":1, \"Female\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94a2632e-66cf-4f32-81dd-35c44b5e69de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_pat_res, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff08d5-4fa2-4b57-bc5a-7a7e5843b38a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comorbidities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "015eb5f9-6375-4c5b-b56c-9cacae2058bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pmh_doac = pd.read_csv(\"data_pneumonia_doac/pastHistory_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "060e774d-dd70-41de-9b75-a8229cfa5a36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "df_pmh_result = get_pastHistory(df_pmh_doac, lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67f1865f-197a-45d4-bd64-c55129b163b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing the PMH variables (aggregating/binarizing)\n",
    "df_pmh_result['pmh_PE_binary'] = df_pmh_result.pmh_PE.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result['pmh_venous_thrombosis_binary'] = df_pmh_result.pmh_venous_thrombosis.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result['pmh_strokes_binary'] = df_pmh_result.pmh_strokes.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result['pmh_mmunosuppression_last_6m_binary'] = df_pmh_result.pmh_mmunosuppression_last_6m.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result['pmh_CHF_binary'] = df_pmh_result.pmh_CHF.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result['pmh_card_valvular_binary'] = df_pmh_result.pmh_card_valvular.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result[\"pmh_afib\"] = df_pmh_result.pmh_arrhythmias.map(lambda x: 1 if \"atrial fibrillation\" in str(x) else 0).astype('int64')\n",
    "df_pmh_result[\"pmh_HT_binary\"] = df_pmh_result.pmh_HT_with_treatment.map(lambda x: 1 if x!=0 else 0).astype('int64')\n",
    "df_pmh_result[\"pmh_coronary_artery_disease\"] = df_pmh_result.apply(lambda x: 1 if (x.pmh_MI!=0 or \n",
    "                                                                                   x.pmh_PCI!=0 or \n",
    "                                                                                   x.pmh_CA_bypass!=0 or\n",
    "                                                                                   x.pmh_angina!=0) else 0, axis=1).astype('int64')\n",
    "df_pmh_result['pmh_home_o2_binary'] = df_pmh_result.pmh_home_o2.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result[\"pmh_copd_binary\"] = df_pmh_result.pmh_COPD.map(lambda x: 1 if x!=0 else 0).astype('int64')\n",
    "df_pmh_result[\"pmh_asthma_binary\"] = df_pmh_result.pmh_asthma.map(lambda x: 1 if x!=0 else 0).astype('int64')\n",
    "df_pmh_result[\"pmh_obstructive_LD\"] = df_pmh_result.apply(lambda x: 1 if (x.pmh_copd_binary!=0 or x.pmh_asthma_binary!=0) else 0, axis=1).astype('int64')\n",
    "df_pmh_result['pmh_cancer_binary'] = df_pmh_result.pmh_cancer.map(lambda x: 0 if (x == 0 or x == \"0\") else 1).astype('int64')\n",
    "df_pmh_result[\"pmh_diabetes_binary\"] = df_pmh_result.apply(lambda x: 1 if (x.pmh_non_insulin_dep_DM!=0 or x.pmh_insulin_dep_DM!=0) else 0, axis=1).astype('int64')\n",
    "df_pmh_result[\"exclude_pmh_dialysis\"] = df_pmh_result.pmh_renal_failure.map(lambda x: 1 if any(s in str(x) for s in [\"hemodialysis\", \"peritoneal dialysis\"]) else 0).astype('int64')\n",
    "df_pmh_result[\"pmh_prior_renal_insufficiency\"] = df_pmh_result.apply(lambda x: 1 if (x.pmh_renal_failure==\"renal failure- not currently dialyzed\" or x.pmh_renal_insuff!=0) else 0, axis=1).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0873bde6-c162-4531-b6c1-a1141cc2242e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_pmh_result, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8fd04-3400-433a-8a11-7cf1d9fb6233",
   "metadata": {
    "tags": []
   },
   "source": [
    "## APACHE variables and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750288c6-5fbe-4730-b965-ae95a4c7715a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apache_res_doac = pd.read_csv(\"data_pneumonia_doac/apachePatientResult_pn_doac.csv\", low_memory=False)\n",
    "df_apache_aps_doac = pd.read_csv(\"data_pneumonia_doac/apacheApsVar_pn_doac.csv\", low_memory=False)\n",
    "df_apache_pred_doac = pd.read_csv(\"data_pneumonia_doac/apachePredVar_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b062eab8-e39f-44a7-a5cb-f31e5e4d6af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apache_res_res = get_cleaned_apachePatientResult_basics(df_apache_res_doac, lst_pat_pneumonia)\n",
    "df_apache_aps_res = get_and_initial_clean_apacheApsVar(df_apache_aps_doac, lst_pat_pneumonia)\n",
    "df_apache_pred_res = get_cleaned_apachePredVar_basics(df_apache_pred_doac, lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2abc827-ebf5-42ec-bee5-1bfa46c1ae49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframes to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_apache_res_res, how=\"left\", on=\"patientunitstayid\")\n",
    "df_info = df_info.merge(right=df_apache_aps_res, how=\"left\", on=\"patientunitstayid\")\n",
    "df_info = df_info.merge(right=df_apache_pred_res, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "512551b0-f46b-4514-b54a-d86e706d5acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ventilation days for patients that survived\n",
    "df_info[\"vent_days_alive\"] = df_info.apply(lambda x: x.unabridgedactualventdays if x.hospitaldischargestatus == 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754abb8-76fc-4fa0-98f7-d9acc8b53ff7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea415a7-e08b-4592-8af9-2bebb6198679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labs = pd.read_csv(\"data_pneumonia_doac/lab_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6626a1da-5435-4e29-a205-60a38de3ef4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# the value lists contain the possible borders as the first tuple, then \"realistic\" borders as the second tuple and then the aggregation method as a string -> worst value on admission\n",
    "dict_labs = {\"BUN\": [(0, 1000), (1, 200), \"max\"]}\n",
    "\n",
    "df_labs_results = fast_clean_labs_general_offset(df_labs=df_labs, \n",
    "                                                        lst_ids=lst_pat_pneumonia, \n",
    "                                                        offsets=(-1440, 1440), \n",
    "                                                        dict_labs_info=dict_labs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bbdb788-8f6f-4d09-8583-6354d6b48d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_labs_results, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b91c77-b4b5-4fae-b19b-8684cbe2ba72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vital signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1063eaa-79ab-477a-b482-d254edfade08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_periodic = pd.read_csv(\"data_pneumonia_doac/vitalPeriodic_pn_doac.csv\", low_memory=False)\n",
    "df_a_periodic = pd.read_csv(\"data_pneumonia_doac/vitalAperiodic_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4ddda79-8413-4ef5-8dac-2c25e9b51ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:37<00:00, 72.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:59<00:00, 59.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# dictionaries of extreme vitals that were excluded as outliers and the aggreagation method\n",
    "dict_vitals_periodic = {\n",
    "    \"heartrate\": [(20, 220), \"max\"],\n",
    "    \"respiration\": [(3, 80), \"max\"],\n",
    "    \"sao2\": [(60, 100), \"min\"]\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": [(20, 250), \"min\"],\n",
    "    \"diastolic\": [(5, 180), \"min\"],\n",
    "}\n",
    "\n",
    "lst_clms_doac_vitals = []\n",
    "\n",
    "# for the \"periodic\" vitals\n",
    "for key, values in tqdm(dict_vitals_periodic.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "    \n",
    "    df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat_pneumonia, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30)\n",
    "\n",
    "    lst_clms_doac_vitals.append(df_temp)\n",
    "\n",
    "# for vital \"systolic\" and \"diastolic\" that uses both the periodic and aperiodic datafiles\n",
    "for key, values in tqdm(dict_vitals_combined.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "\n",
    "    df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                   df_aperiodic=df_a_periodic,\n",
    "                                   lst_ids=lst_pat_pneumonia, \n",
    "                                   vital_name=key, \n",
    "                                   realistic_bounds=realistic, \n",
    "                                   offset=(0, 1440), \n",
    "                                   agg_total=direction, \n",
    "                                   timeunit=30)\n",
    "\n",
    "    lst_clms_doac_vitals.append(df_temp)\n",
    "\n",
    "lst_clms_doac_vitals_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_doac_vitals]\n",
    "df_final_vitals_doac = pd.concat(lst_clms_doac_vitals_indexed, axis=1)\n",
    "\n",
    "df_final_vitals_doac = df_final_vitals_doac.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7211b2e-d56c-40af-a812-cd8faa89b25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_final_vitals_doac, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd3fe7-5db4-4a29-ab5d-6024f00d19e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ICU-free-days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aaa615d6-0147-469d-8236-0f0e9cc376eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_icu_free_days = get_icu_free_days(df_patient_doac, lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "beb348fc-87c8-485c-a6aa-52c299a8691e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_icu_free_days, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bd036-0b22-42de-82c8-02534df9cc96",
   "metadata": {},
   "source": [
    "## Vasopressor/Inotrope infusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac814a53-806f-4401-b56c-ff7d55c12bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_infusion_doac = pd.read_csv(\"data_pneumonia_doac/infusionDrug_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ea03205-378f-46a7-8b3e-622833e32620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vaso_ino_d1 = get_infusion_drugs(df_infusion_doac, lst_pat_pneumonia)\n",
    "df_vaso_ino_d1 = df_vaso_ino_d1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb87ffa1-1e8f-45b5-946c-44b7abca6670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_vaso_ino_d1, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de0de6-1975-4168-a75b-1987d59582ce",
   "metadata": {},
   "source": [
    "## Time-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1cc84f5-7524-45ec-8307-68b3d7cd9bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_time_to_death = time_to_death_from_unit_admission(df_pat=df_patient_doac, df_apache_res=df_apache_res_doac, lst_ids=lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6d60ef7-caeb-4e1d-b643-edc43443f490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframes to the growing final dataframe\n",
    "df_info = df_info.merge(\n",
    "    right=df_time_to_death,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f30877-77e1-4a59-b1bc-48090c83ccc3",
   "metadata": {},
   "source": [
    "## AKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f81e81a-4bde-4dce-872a-cb2d9e59bf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_diagnosis_doac = pd.read_csv(\"data_pneumonia_doac/diagnosis_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c2ca5a2-e3e8-4602-b555-8f6288efd218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_aki_result = find_AKI_pat(df_labs, df_diagnosis_doac, lst_pat_pneumonia)\n",
    "df_aki_result = df_aki_result.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0dfbebb-aca4-4054-8c58-a955ab93b376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processing to see who should had an AKI on admission/on their first day and who developed AKI during the ICU-/hospitalstay\n",
    "def map_aki_crea_rise_firstday(x):\n",
    "    \"\"\"Function that computes whether patients with an AKI based on a rise in their creatinine levels had\n",
    "    that AKI in the first 24h (1440 minutes) after admission to the ICU\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        lst_offsets = x.split(\"|\")\n",
    "\n",
    "        lst_firstday_offsets = [int(i) for i in lst_offsets if int(i) <= 1440]\n",
    "\n",
    "        if len(lst_firstday_offsets) >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# determine who had AKI defined by a rise in creatinine on the first day on ICU\n",
    "df_aki_result[\"crea_rise_first_day\"] = df_aki_result[\"AKI_crea_rise_offsets\"].map(lambda x: map_aki_crea_rise_firstday(x))\n",
    "\n",
    "# create a column that denotes whether patients got an AKI on the first day or were already diagnosed with AKI on admission\n",
    "df_aki_result[\"fist_day_or_admission_aki\"] = df_aki_result.apply(lambda x: 1 if (x.AKI_diagnosis_onadmission == 1 or x.crea_rise_first_day == 1) else 0, axis=1)\n",
    "\n",
    "# create a column that identifies patients that did not have any information regarding AKI (no creatinine levels)\n",
    "df_aki_result[\"NA_in_crea_rise_and_baseline\"] = 0\n",
    "df_aki_result.loc[(df_aki_result.AKI_crea_rise.isna()) & (df_aki_result.AKI_crea_baseline.isna()), \"NA_in_crea_rise_and_baseline\"] = 1\n",
    "\n",
    "# make the final AKI column whether patients had an AKI\n",
    "df_aki_result[\"aki_wo_firstday_or_admission\"] = 0 # set everyone to 0\n",
    "df_aki_result.loc[(df_aki_result.AKI_crea_rise == 1) | (df_aki_result.AKI_crea_baseline == 1) | (df_aki_result.AKI_diagnosis_ever == 1),\n",
    "                   \"aki_wo_firstday_or_admission\"] = 1 # set everyone with any type of AKI to 1\n",
    "df_aki_result.loc[(df_aki_result.NA_in_crea_rise_and_baseline == 1) | (df_aki_result.fist_day_or_admission_aki == 1), \n",
    "                  \"aki_wo_firstday_or_admission\"] = np.nan  # set anyone that had an AKI on the first day or the admission, or who did not have any data to np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae760606-e4ca-4bba-963c-8a7efc108797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframes to the growing final dataframe\n",
    "df_info = df_info.merge(right=df_aki_result, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5ebbb-d23d-449e-92a2-d5f9202d7b8f",
   "metadata": {},
   "source": [
    "## Intubated on admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d78ac0d5-ea42-4cdf-bc01-2d5905d76006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_intub_in_hosp_or_ICU(x):\n",
    "    \"\"\"Function that determines whether patients were intubated during the first 24h on admission\"\"\"\n",
    "    \n",
    "    if pd.isna(x.pred_oobintubday1):\n",
    "        return np.nan\n",
    "    if x.pred_oobintubday1 == 0:\n",
    "        return 0\n",
    "    if x.pred_oobintubday1 == 1:\n",
    "        if x.unitadmitsource in ['Emergency Department', 'Floor', 'Direct Admit', 'Step-Down Unit (SDU)', 'Acute Care/Floor', 'Recovery Room', 'PACU']:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1 # patients that were intubated at some time during the first 24h but, based on their unitadmitsource (e.g. Other hospital, other ICU etc.), \n",
    "                      # were intubated before reaching this unit/hospital\n",
    "\n",
    "df_info[\"fresh_intub_on_admission\"] = df_info.apply(lambda x: apply_intub_in_hosp_or_ICU(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cdc82-035c-4afb-a124-e1027e7a1c47",
   "metadata": {},
   "source": [
    "## RRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d2cd166-58c1-4eaf-ab76-efe8dab95cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_treatment_doac = pd.read_csv(\"data_pneumonia_doac/treatment_pn_doac.csv\", low_memory=False)\n",
    "df_intout_doac = pd.read_csv(\"data_pneumonia_doac/intakeOutput_pn_doac.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6a4e641-1818-40d8-9a6d-c62b08188160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "df_dialysis_res = get_dialysis_dialysisdays(df_intout=df_intout_doac, df_treat=df_treatment_doac, df_pmh=df_pmh_doac, lst_ids=lst_pat_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6144c08-2198-44b2-8ddf-855944b93459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_only_new_dialysis(x):\n",
    "    \"\"\"Function that determines whether patients started new RRT on ICU or were on chronic dialysis\"\"\"\n",
    "    if x.any_dialysis_ever == 0:\n",
    "        return 0\n",
    "    if x.any_dialysis_ever == 1:\n",
    "        if x.pmh_dialysis == 0 and x.treatment_chronic_dialysis == 0 and x.treatment_peritoneal_dialysis == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_dialysis_res[\"new_acute_dialysis\"] = df_dialysis_res.apply(lambda x: apply_only_new_dialysis(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "378b3707-e57f-4602-abbb-3f69849a68e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_info = df_info.merge(right=df_dialysis_res, how=\"left\", on=\"patientunitstayid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a572eb-34b9-446c-a0f3-f7b77726b529",
   "metadata": {},
   "source": [
    "# Patient exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1e81103-263a-4a4a-8019-0f92e55e7a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11317"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0220190a-6b48-4d0e-9e19-96dcaff49e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11305"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude any non-adult patients\n",
    "df_info_excl_age = df_info[df_info.age >= 18].copy()\n",
    "\n",
    "len(df_info_excl_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "820759e2-3e51-4e07-a5d5-dca0aae3c4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10765"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude any patients who were intubated before arriving at this hospital/ICU and who had a history of dialysis\n",
    "df_info_excl_outcomes = df_info_excl_age.loc[(df_info_excl_age.fresh_intub_on_admission != (-1)) & \n",
    "                                               (df_info_excl_age.exclude_pmh_dialysis != 1) &\n",
    "                                               (df_info_excl_age.treatment_chronic_dialysis != 1) &\n",
    "                                               (df_info_excl_age.treatment_peritoneal_dialysis != 1), :].copy()\n",
    "\n",
    "len(df_info_excl_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e17f0e5-a39b-4585-b74e-a5bbe9c19548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8118"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude any patients with missing data in the survival outcomes and the propensity score matching variables (PSM requires complete data)\n",
    "clms_na_drop = [\n",
    "    'hospitaldischargestatus',\n",
    "    'unitdischargestatus',\n",
    "    'apacheadmissiondx',\n",
    "    'gender',\n",
    "    'pmh_coronary_artery_disease',\n",
    "    'pmh_CHF_binary',\n",
    "    'pmh_afib',\n",
    "    'pmh_obstructive_LD',\n",
    "    'pmh_home_o2_binary',\n",
    "    'pmh_diabetes_binary',\n",
    "    'pmh_prior_renal_insufficiency',\n",
    "    'pmh_cancer_binary',\n",
    "    'pmh_HT_binary',\n",
    "    'pmh_card_valvular_binary',\n",
    "    'pmh_PE_binary',\n",
    "    'pmh_venous_thrombosis_binary',\n",
    "    'pmh_strokes_binary',\n",
    "    'pmh_mmunosuppression_last_6m_binary',\n",
    "    'age',\n",
    "    'apachescore',\n",
    "    'BUN_-1440to1440_max',\n",
    "    'respiration_max_0to1440_u30',\n",
    "    'systolic_min_0to1440_u30',\n",
    "    'heartrate_max_0to1440_u30',\n",
    "    'sao2_min_0to1440_u30',\n",
    "    'diastolic_min_0to1440_u30',\n",
    "    'aps_GCS' \n",
    "]\n",
    "\n",
    "df_info_excl_missingdata = df_info_excl_outcomes.dropna(subset=clms_na_drop)\n",
    "\n",
    "len(df_info_excl_missingdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a02268-7d9b-49b8-8de3-0542f1ef864d",
   "metadata": {},
   "source": [
    "# Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48258685-ed5e-4aa8-aae9-c9e16cf57cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_info_excl_missingdata.to_csv(\"data_pneumonia_doac/doac_data_extraction_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
